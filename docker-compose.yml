services:
  airflow-webserver: &airflow
    container_name: airflow-webserver
    build: 
      context: ./airflow
      dockerfile: Airflow.dockerfile
    environment:
      AIRFLOW_USER: admin
      AIRFLOW_PASSWORD: admin
      AIRFLOW___CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW___CORE__EXECUTOR: LocalExecutor
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./jars:/opt/spark/jars
    ports:
      - "8080:8080"
    command: webserver
    networks:
      - default_network
    depends_on:
      - postgres

  airflow-scheduler:
    <<: *airflow
    container_name: airflow-scheduler
    command: scheduler
    ports: []

  minio:
    container_name: object-storage
    image: quay.io/minio/minio:latest
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: admin
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 1m30s
      timeout: 30s
      retries: 5
      start_period: 30s
  
  minio-setup:
    container_name: minio-setup
    build:
      context: ./minio
      dockerfile: Minio.dockerfile
    environment:
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: admin
    depends_on:
      minio:
        condition: service_healthy
  
  postgres:
    container_name: postgres
    image: postgres:15
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - ./postgres:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"

  spark-master: &spark
    container_name: spark-master
    build:
      context: ./spark
      dockerfile: Spark.Dockerfile
    environment:
      SPARK_MODE: master
      SPARK_EXTRA_CLASSPATH: /opt/bitnami/spark/additional-jars/*
    ports:
      - "8090:8080"
      - "7077:7077"
    networks:
      - default_network

  spark-worker:
    <<: *spark
    container_name: spark-worker
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_CORES: 1
    depends_on:
      - spark-master
    ports: []

volumes:
  minio_data:

networks:
  default_network:
